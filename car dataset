# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Step 1: Load the dataset
data = pd.read_csv('Craigslist Car Dataset.csv')

# Step 2: Data exploration
print(data.head())
print(data.info())
print(data.describe())

# Step 3: Handling missing values
data = data.dropna()  # Drop rows with missing values for simplicity

# Step 4: Feature Engineering
# Create a new feature 'Car_Age' based on the current year
data['Car_Age'] = 2024 - data['year']

# Drop irrelevant or less useful columns (like 'year', if we have 'Car_Age')
data = data.drop(columns=['year'])

# Step 5: Handle categorical variables using one-hot encoding
categorical_features = ['condition']
numeric_features = ['Car_Age', 'odometer']

# Use ColumnTransformer to handle different types of preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('numerical', StandardScaler(), numeric_features),
        ('categorical', OneHotEncoder(drop='first'), categorical_features)
    ])

# Step 6: Split the data into training and testin
